#notes

https://en.wikipedia.org/wiki/Ext4

Unlimited number of subdirectories
    ext4 does not limit the number of subdirectories in a single directory, except by the inherent size limit of the directory itself. (In ext3 a directory can have at most 32,000 subdirectories.)[16][obsolete source] To allow for larger directories and continued performance, ext4 in Linux 2.6.23 and later turns on HTree indices (a specialized version of a B-tree) by default, which allows directories up to approximately 10–12 million entries to be stored in the 2-level HTree index and 2 GB directory size limit for 4 KiB block size, depending on the filename length. In Linux 4.12 and later the large_dir feature enabled a 3-level HTree and directory sizes over 2 GB, allowing approximately 6 billion entries in a single directory.

https://documentation.suse.com/sle-ha/12-SP5/html/SLE-HA-all/art-ha-quick-nfs.html

https://documentation.suse.com/zh-cn/sle-ha/15-SP3/single-html/SLE-HA-nfs-storage/#article-nfs-storage

https://documentation.suse.com/zh-cn/sle-ha/15-SP3/single-html/SLE-HA-nfs-storage/#article-nfs-storage


earlyprintk=serial,ttyS0,115200 loglevel=8 initcall_debug 

(gdb) list *kernel_init_freeable+0x1a2      
0xffffffff8256240a is in kernel_init_freeable (../init/main.c:882).
877                        __stop___param - __start___param,
878                        level, level,
879                        NULL, &repair_env_string);
880
881             for (fn = initcall_levels[level]; fn < initcall_levels[level+1]; fn++)
882                     do_one_initcall(*fn);
883     }
884
885     static void __init do_initcalls(void)
886     {


vg恢复步骤：(前提是首先remove去掉所有的lvm)
1.根据/etc/lvm/backup中的vg0 信息恢复
2.首先重新一个个创造pv, 根据vg0中的对应pv uuid:
pvcreate /dev/sda -u (uuid) --restorefile /etc/lvm/backup/vg0
pvcreate /dev/sdb -u (uuid)—restorefile /etc/lvm/backup/vg0
3.vgcfgrestore vg0 (自动寻找/etc/lvm/backup/中的vg
4.lvs查看lv状态，此时应该没有a激活状态，而且没有/dev/vg0/lv...信息）
5.激活vg vgchange -ay vg0 (去激活是 vgchange -an vg0)

# /usr/bin/last -xF | egrep "reboot|shutdown|runlevel|system"

审计bug:
https://www.suse.com/support/kb/doc/?id=000021152

What is the meaning of "ext[3/4]_dx_add_entry: Directory index full!"?
https://access.redhat.com/solutions/29894

latest curl:
curl-8.0.1-11.86.2.src.rpm	
curl-8.0.1-11.86.2.x86_64.rpm	
libcurl4-32bit-8.0.1-11.86.2.x86_64.rpm	
libcurl4-8.0.1-11.86.2.x86_64.rpm

zcat /proc/config.gz | grep CONFIG_NET_VENDOR_RENESAS
CONFIG_NET_VENDOR_RENESAS=y

docker-24.0.7_ce-98.106.1.x86_64.rpm
https://bugzilla.suse.com/show_bug.cgi?id=1219267

NFS4ERR_CLID_INUSE = 10017,




static const struct nfs4_state_recovery_ops nfs40_reboot_recovery_ops = {
        .owner_flag_bit = NFS_OWNER_RECLAIM_REBOOT,
        .state_flag_bit = NFS_STATE_RECLAIM_REBOOT,
        .recover_open   = nfs4_open_reclaim,
        .recover_lock   = nfs4_lock_reclaim,
        .establish_clid = nfs4_init_clientid,                 // for 4.0
        .detect_trunking = nfs40_discover_server_trunking,
};

#if defined(CONFIG_NFS_V4_1)
static const struct nfs4_state_recovery_ops nfs41_reboot_recovery_ops = {
        .owner_flag_bit = NFS_OWNER_RECLAIM_REBOOT,
        .state_flag_bit = NFS_STATE_RECLAIM_REBOOT,
        .recover_open   = nfs4_open_reclaim,
        .recover_lock   = nfs4_lock_reclaim,
        .establish_clid = nfs41_init_clientid,                            // for  v4.1
        .reclaim_complete = nfs41_proc_reclaim_complete,
        .detect_trunking = nfs41_discover_server_trunking,
};


For NFS 4.0:  (sles12sp5 4.12.14-122.186)
 nfs4_proc_setclientid
        if (test_bit(NFS_CS_MIGRATION, &clp->cl_flags))
                status = nfs4_init_uniform_client_string(clp);
        else
                status = nfs4_init_nonuniform_client_string(clp);

linux-miqc:/sys/module/nfs/parameters # echo 'test-nfs'> ./nfs4_unique_id 

mount -t nfs -o vers=4.0 192.168.2.77:/issues/ /issues/        （ 未上migration选项）
dmesg | grep "setclientid"
[345994.085989] NFS call  setclientid auth=UNIX, 'Linux NFSv4.0 192.168.2.25/192.168.2.77 tcp'


 mount -t nfs -o vers=4.0,migration  192.168.2.77:/issues/ /issues/     (加上migration选项）
#dmesg | grep "setclientid"
[346041.242784] NFS call  setclientid auth=UNIX, 'Linux NFSv4.0 test-nfs


在使用nfs4.0挂载选项有migration，clientid才会包含nfs4_unique_id  参数



For NFS 4.1:  (sles12sp5 4.12.14-122.186)

nfs41_init_clientid()
       nfs4_init_uniform_client_string()

static int
nfs4_init_uniform_client_string(struct nfs_client *clp)
{
        size_t len; 
        char *str;

        if (clp->cl_owner_id != NULL)
                return 0;

        if (nfs4_client_id_uniquifier[0] != '\0')
                return nfs4_init_uniquifier_client_string(clp);

        len = 10 + 10 + 1 + 10 + 1 +
                strlen(clp->cl_rpcclient->cl_nodename) + 1; 

        if (len > NFS4_OPAQUE_LIMIT + 1) 
                return -EINVAL;

        /*   
         * Since this string is allocated at mount time, and held until the
         * nfs_client is destroyed, we can use GFP_KERNEL here w/o worrying
         * about a memory-reclaim deadlock.
         */
        str = kmalloc(len, GFP_KERNEL);
        if (!str)
                return -ENOMEM;

        scnprintf(str, len, "Linux NFSv%u.%u %s",
                        clp->rpc_ops->version, clp->cl_minorversion,
                        clp->cl_rpcclient->cl_nodename);
        clp->cl_owner_id = str; 
        return 0;
}

而对于nfs v4.1  如果设置了nfs4_unique_id，clientid会获取设置的nfs4_unique_id参数


 # openssl x509 -in thawte_Primary_Root_CA_-_G2.pem -noout -text

NFSv4.1 has various improvements relating to state management and opening file.
